{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the optimal statistic with `enterprise_extensions`\n",
    "\n",
    "* In this notebook you will learn how to compute the optimal statistic (OS). \n",
    "* The optimal statistic is a frequentist detection statistic for the stochastic background.\n",
    "* It assesses the significance of the cross-correlations and compares them to the Hellings-Downs curve.\n",
    "\n",
    "* For more information, see [Anholm et al. 2009](https://arxiv.org/abs/0809.0701), [Demorest et al. 2013](https://arxiv.org/abs/1201.6641), [Chamberlin et al. 2015](https://arxiv.org/abs/1410.8256), [Vigeland et al. 2018](https://arxiv.org/abs/1805.12188), [Sardesei and Vigeland 2023]()\n",
    "\n",
    "* The OS is derived under the assumption of the low-SNR regime on the GWB\n",
    "\n",
    "* This works well as a detection statistic, because we work under the null hypothesis that $\\hat{A}_\\text{gw}^2 = 0$\n",
    "\n",
    "* See [Allen 2023]() and [Allen and Romano 2023]() for changes to the OS that take GWB covariance into account which are required to use the OS as an unbiased estimator of $\\hat{A}_\\text{gw}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Warning: cannot find astropy, units support will not be available.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import glob, json, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from enterprise_extensions import models\n",
    "from enterprise_extensions.frequentist import optimal_statistic as opt_stat\n",
    "\n",
    "from h5pulsar.pulsar import FilePulsar\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pulsar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    datadir = '/content/12p5yr_stochastic_analysis/tutorials/data'\n",
    "else:\n",
    "    datadir = './data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-component optimal statistic as a detection statistic\n",
    "\n",
    "* The original OS assumes a single correlation component\n",
    "\n",
    "* This means we could search for\n",
    "  * monopolar correlations, such as those that may come from clock corrections\n",
    "  * dipolar correlations, such as those that may come from ephemeris modeling errors\n",
    "  * or HD correlations, such as those created by a stochastic gravitational wave background\n",
    "\n",
    "* If we want to search for all of these simultaneously to prevent leakage from one component into another, we need to use the multiple component OS (MCOS) and search for all three of these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 67 pulsars from hdf5 files\n"
     ]
    }
   ],
   "source": [
    "psrs = []\n",
    "for hdf5_file in glob.glob(datadir + '/hdf5/*.hdf5'):\n",
    "    psrs.append(FilePulsar(hdf5_file))\n",
    "print('Loaded {0} pulsars from hdf5 files'.format(len(psrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get parameter noise dictionary\n",
    "noise_ng15 = datadir + '/15yr_wn_dict.json'\n",
    "\n",
    "wn_params = {}\n",
    "with open(noise_ng15, 'r') as fp:\n",
    "    wn_params.update(json.load(fp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `enterprise_extensions` to make a model with a common red process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Note: It will take a few minutes to run this cell and may require at least ~4GB RAM)\n",
    "# This will NOT work if we use tm_marg=True, so we don't use it here.\n",
    "pta = models.model_2a(psrs, noisedict=wn_params, n_gwbfreqs=14, tm_svd=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the optimal statistic object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = opt_stat.OptimalStatistic(psrs, bayesephem=False, noisedict=wn_params, pta=pta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we use the noise-marginalized version of the optimal statistic\n",
    "* This is a version of the OS that averages the noise over an MCMC chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.compute_noise_marginalized_multiple_corr_os()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosettaprise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
